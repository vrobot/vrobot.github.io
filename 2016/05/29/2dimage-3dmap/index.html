<!DOCTYPE html>
<html>

  <head>
  <title>Venkat Krishnan | Obstacle Avoidance</title>
  <meta charset="utf-8">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <meta name="description" content="This blog has some thoughts and projects that I've been working on recently. If you'd like to share some ideas on topics I've posted, email me at vkrishnan [at] ucsb.edu">
	<meta property="og:title" content="The Adventures of Venkat Krishnan"/>
    <meta property="og:url" content="https://vrobot.github.io"/>
    <meta property="og:site_name" content="The Adventures of Venkat Krishnan"/>
    <meta property="og:type" content="blog"/>
    <meta property="og:description" content="This blog has some thoughts and projects that I've been working on recently. If you'd like to share some ideas on topics I've posted, email me at vkrishnan [at] ucsb.edu">
    <meta property="og:image" content="https://vrobot.github.io/img/profile.jpg">  
 
  <link rel="canonical" href="https://vrobot.github.io/2016/05/29/2dimage-3dmap/">
  <link rel="shortcut icon" href="../../../../img/favicon.ico">
  <link rel="stylesheet" href="../../../../css/main.css">
  <link rel="stylesheet" href="../../../../css/syntax.css">
  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900,200italic,300italic,400italic,600italic,700italic,900italic&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:200,300,400,500,600,700,900&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
  
  	<!-- The next section is for google authentication -->
	<meta name="google-site-verification" content="Kc8BTwj09E0jhjhIN29d7hZAkQPLDMQJyw5QFse_FQA" />
	
	<meta name="google-site-verification" content="2M8vRUQygiHkoVcm83x05Dsi2CFWe_VnF67gYtoJzCI" />
		
	<meta name="google-signin-client_id" content="523796096613-g7rilrn4nkiclnok6jrmo7bl9gevovlv.apps.googleusercontent.com">
	
	<script src="https://apis.google.com/js/platform.js" async defer></script>
	
	
	
	<!-- Google authentication code is in the above section -->
	
	<!-- Google Analytics -->
	
	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-80729776-1', 'auto');
  ga('send', 'pageview');

</script>
	
	<!-- End of Google Analytics code -->
  
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
<h1><a href="../../../../">Hi! I'm Venkat Krishnan.</a></h1>
	  <h1><a href="../../../../">I'm interested in Science and Technology and enjoy working on projects in these areas.</a></h1>
	<p class="tagline">&nbsp;</p>
    </div>

  <!--  <input type="checkbox" id="menu-icon"> -->
    <label class="menu-label" for="menu-icon"></label>
    <div class="trigger">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-item active">
          <a href="../../../../">Home</a>
		  
		  
		  
		  <span> | </span>
		  
		  
		  
		  <a href="../../../../about/">About Me</a>
		  
        </li>

            
              
           
         

      </ul>
    </div>

    <p class="copyright">Â© 2018 Venkat Krishnan. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
 
	
 
  <div class="post">
   <div class="post">
    <h1 class="post-title">
      <a href="./">
        Three Dimensional Mapping from Two Dimensional Images from a Single Point-Of-Focus for Obstacle Avoidance
      </a>
    </h1>

    <span class="post-date">29 May 2016</span>


<p>Obstacle avoidance has long been one of the biggest challenges in the field of computer vision and it holds tremendous value for its applications in the field - from self-driving cars to wearable tech for the visually impaired and autonomous drones for emergency response. Currently there are some available algorithms for this task but they take input from multiple cameras from multiple points-of-focus, therefore exponentially increasing the data that needs to be processed and requiring costly, high-powered computers to process the algorithms, making them impractical to be used on wearable technology and light-weight autonomous drones. For the past couple years, this topic has seized my interest and I've been researching a lot about it.</p>

<h3>Why Cameras? Can't Simple Ultrasonic Sensors Be Used? </h3>

<p>When I first started reading about this problem, this was the first thought that came to my mind. The problem initially seemed simple. Let's consider the case of an autonomous car. We place one ultrasonic sensor on each side of the car and we can continuously measure the distance the car is from obstacles on each side and use those values in an algorithm to avoid obstacles. However, there are multiple flaws with this basic methodology. But before I go on explaining these problems, let's take a step back and first understand how the ultrasonic sensor works.</p>

<h3>How the Ultrasonic Sensor Works and its Flaws</h3>

<p>The basis of the technology inside the ultrasonic sensor is very similar to how bats use echo location to navigate in the night. The ultrasonic sensor sends a sound wave, typically between 25kHz and 500kHz, and times how long it takes for the wave to hit an object and bounce back to the sensor's ping reciever. To calculate the distance traveled by the sound wave we can use: <script type='math/tex'>d=\frac{v_{sound}\times{t}}{2}</script>, where <script type='math/tex'>d</script> is the distance from the object and the sensor, <script type='math/tex'>v_{sound}</script> is the average speed of sound constant and <script type='math/tex'>t</script> is the time elasped from when the initial ping was released to when the ping was recieved back.</p>



<p><a href="https://vrobot.github.io/2016/05/29/2dimage-3dmap/ultrasonic2.png"><img src="./ultrasonic2.png" title="Ultrasonic Sensor" alt="Ultrasonic Sensor"/></a></p>

<h6>How an Ultrasonic Sensor Works. Figure borrowed from Aimagin.</h6>

<p>Now, let's discuss some of the fundamental problems with this method:</p>


<p>
<ol>
<li>In this method we use the speed of sound as a constant. However, the speed of sound changes depending on the medium through which the sound is traveling. To factor in this additional variable of the medium through which the sound is traveling additional sensors, such as a gas sensor, should be added to the car. For example, if the gas sensor gives a high ppm reading for <script type='math/tex'>CO_2</script> concentration in the air, accordingly, a different constant will be used for the speed of sound.</li>

<li>The sound wave is not only traveling through air, but also hitting an object and bouncing back to the sensor. Depending on the material composition of the object, the object can either absorb the sound wave, change the frequency of the sound wave, or change the angle of the sound wave so that it does not return to the sensor. In a practical situation, if we have an autonomous car driving around a neighborhood, it's hard to control what objects the sound waves hit and it is difficult to get a good approximation for the speed of sound constant.</li>

<li>Unlike cameras, ultrasonic sensors don't have a "wide-angle". What I am getting to here is ultrasonic sensors can only measure the distance from an object directly in front of it. If we only had one sensor on each side of the car, we would only be measuring the distance from an object that is directly in front of the sensors. Therefore to be of any use, we would need to place several sensors spanning throughout each side of the car. With this the data needed to be processed increases significantly and due to the other two problems listed above, it will still not be accurate enough for practical use.</li>
</ol>
</p>

<h3>Optical Flow Modeling With Multiple Cameras - Data Processed Increases Exponentially</h3>

<p>Currently, there are a few methods to use multiple cameras to create a three dimensional map of the environment around the car with relative locations of obstacles to the car's position. Here is a general overview of the process:</p>




<p>
<ol>
<li>As car moves forward, initial images from both cameras are taken. The images are blurred, warped, and grayscaled. Guassian pyramids are created to model optical flow.</li>
<li>As car continues to move forward, vectors are drawn to model motion.</li>
<li>Trigonometric algorithms are used to model location of obstacles based on the camera angle and relative magnitudes of the vectors.</li>
<li>Distance values are used to create a local map of the car's location relative to the obstacles' locations.</li>
</ol>
</p>


<p>
However, there are some limitations that are worth noting:
</p>

<p>
<ol>
<li>Even though we reduce the information that needs to be processed by blurring, warping, and grayscaling the images, there is still a lot to process in real-time.</li>
<li>Since we are using multiple cameras the algorithms are more complex and the data needed to process grows exponentially, making it difficult to run on cheap light-weight platforms.</li>
</ol>
</p>






<h3>Monocular Mapping of a Three Dimensional Environment Using a Single Camera</h3>

<p>Due to limitations becuase of the exponential increase in the computing load with multiple cameras, a new field of study, monocular mapping, which uses a single camera to map a multi-dimensional environment is being researched. For the past year, my curiousity has been captured by this field and I've created a base set of novel algorithms that can do this task fairly well. They're not computationally intense and can be processed on low-cost embedded systems. Although monocular mapping is currently in its initial stages of studying, I believe it can have a huge imapct on the world at large - obstacle avoidance algorithms can be processed on tiny embedded systems for applications from autonomous cars to wearable technology for the visually impaired!</p>








<h3>Conclusions</h3>

<p>Obstacle avoidance and autonomous navigation continues to be one of the biggest challenges in the field of computer vision. If you're interested and would like to share ideas, please feel free to <a href="mailto:vkrishnan@ucsb.edu">email me.</a> I'm always excited to hear new ideas!

</div>

</div>

<div class="pagination">

    <span class="pagination-item newer">&laquo; Older</span>


	<a class="pagination-item older" href="https://vrobot.github.io/2016/07/03/electric-cars/">Newer &raquo;</a>
  
  <!--
  
    <span class="pagination-item older" href="" &laquo; Older</span>
  
  
    <span class="pagination-item newer" href="" Newer &raquo;</span> -->
	

	
	<!--  <a class="pagination-item newer" <!-- href="" Newer &raquo;</a> -->
  
</div>

    </div>

    <!-- MathJax -->
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<div class="comments">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'venkatkrishnan';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

    </div>


  </body>

  
  <!-- 
  
  Website content Copyright (c) 2016 Venkat Krishnan.

Page formatting credits are below :

Released under MIT License

Copyright (c) 2013 Mark Otto.

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
  
  
  -->
  
  
</html>
